{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "def read_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return '\\n'.join(full_text)\n",
    "\n",
    "file_path = r\"Y:\\Yoshi\\MIDS\\Datasci209\\Projects\\FinalProject\\Data\\ExampleReports\\KCCA CT 12 15 23 Not fatal.docx\"\n",
    "text = read_docx(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\LlamaIndex\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from guardrails.validators import ValidRange, ValidChoices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents\n",
    "documents = SimpleDirectoryReader(\n",
    "input_files = [r\"Y:\\Yoshi\\MIDS\\Datasci209\\Projects\\FinalProject\\Data\\ExampleReports\\KCCACT121523Notfatal.docx\"]\n",
    "#input_files = [r\"Y:\\Yoshi\\MIDS\\Datasci209\\Projects\\FinalProject\\Data\\ExampleReports\\KCCA CT JL 2 25 22 Not Fatal.docx\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define embedding function\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents, chunk_size=512,embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.ollama import Ollama\n",
    "Settings.llm = Ollama(model=\"mistral\", request_timeout=30.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\AppData\\Local\\Temp\\ipykernel_16172\\672115108.py:3: DeprecationWarning: Call to deprecated class StructuredLLMPredictor. (StructuredLLMPredictor is deprecated. Use llm.structured_predict().)\n",
      "  llm_predictor = StructuredLLMPredictor(llm=Ollama(model=\"mistral\", request_timeout=30.0))\n"
     ]
    }
   ],
   "source": [
    "from llama_index.output_parsers.guardrails import GuardrailsOutputParser\n",
    "from llama_index.legacy.llm_predictor import StructuredLLMPredictor\n",
    "llm_predictor = StructuredLLMPredictor(llm=Ollama(model=\"mistral\", request_timeout=30.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.legacy.prompts import PromptTemplate\n",
    "from llama_index.legacy.prompts.default_prompts import (\n",
    "    DEFAULT_TEXT_QA_PROMPT_TMPL,\n",
    "    DEFAULT_REFINE_PROMPT_TMPL,\n",
    ")\n",
    "from pydantic import BaseModel, Field\n",
    "import guardrails as gd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can either define a RailSpec and initialise a Guard object from_rail_string()\n",
    "# OR define Pydantic classes and initialise a Guard object from_pydantic()\n",
    "# For more info: https://docs.guardrailsai.com/defining_guards/pydantic/\n",
    "# Guardrails recommends Pydantic\n",
    "\n",
    "class Point(BaseModel):\n",
    "    # In all the fields below, you can define validators as well\n",
    "    # Left out for brevity\n",
    "    fatal: str = Field(\n",
    "        description=\"did the car theft result in a fatality?\",\n",
    "        validators=[ValidChoices(choices=['Yes','No'], on_fail='reask')]\n",
    "    )\n",
    "    date: str = Field(\n",
    "        description=\"what date did the car theft occur?\"\n",
    "    )\n",
    "    city: str = Field(\n",
    "        description=\"what city did the car theft occur in?\"\n",
    "    )\n",
    "    state: str = Field(\n",
    "        description=\"what state did the car theft occur in?\"\n",
    "    )\n",
    "    location: str = Field(\n",
    "        description=\"business name of where the car theft occurred?\"\n",
    "    )\n",
    "    victim_injuries: str = Field(\n",
    "        description=\"did the victim sustain any injuries?\"\n",
    "    )\n",
    "    victim_injury_type: str = Field(\n",
    "        description=\"if the victim was injured, what type of injuries did the victim sustain?\"\n",
    "    )\n",
    "    victim_count: int = Field(\n",
    "        description=\"how many victims were there?\"\n",
    "    )\n",
    "    victim_sex: str = Field(\n",
    "        description=\"what was the sex of the victim?\"\n",
    "    )\n",
    "    victime_ages: str = Field(\n",
    "        description=\"what were the ages of the victims?\"\n",
    "    )\n",
    "    notes: str = Field(\n",
    "        description=\"summary of what happened along with details of where the car theft occurred and how the child was alone in the car\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# Define the prompt\n",
    "prompt = \"\"\"\n",
    "Extract the information from the news article.\n",
    "\n",
    "${output_schema}\n",
    "\n",
    "${gr.json_suffix_prompt_v2_wo_none}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a guard object\n",
    "guard = gd.Guard.from_pydantic(output_class=Point, prompt=prompt)\n",
    "\n",
    "# Create output parse object\n",
    "output_parser = GuardrailsOutputParser(guard, llm=llm_predictor.llm.complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: we use the same output parser for both prompts, though you can choose to use different parsers\n",
    "# NOTE: here we add formatting instructions to the prompts.\n",
    "\n",
    "fmt_qa_tmpl = output_parser.format(DEFAULT_TEXT_QA_PROMPT_TMPL)\n",
    "fmt_refine_tmpl = output_parser.format(DEFAULT_REFINE_PROMPT_TMPL)\n",
    "\n",
    "qa_prompt = PromptTemplate(fmt_qa_tmpl, output_parser=output_parser)\n",
    "refine_prompt = PromptTemplate(fmt_refine_tmpl, output_parser=output_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context information is below.\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: {query_str}\n",
      "Answer: \n",
      "\n",
      "ng name=\"fatal\" description=\"did the car theft result in a fatality?\" format=\"valid-choices: choices=['Yes', 'No']\"/>\n",
      "    <string name=\"date\" description=\"what date did the car theft occur?\"/>\n",
      "    <string name=\"city\" description=\"what city did the car theft occur in?\"/>\n",
      "    <string name=\"state\" description=\"what state did the car theft occur in?\"/>\n",
      "    <string name=\"location\" description=\"business name of where the car theft occurred?\"/>\n",
      "    <string name=\"victim_injuries\" description=\"did the victim sustain any injuries?\"/>\n",
      "    <string name=\"victim_injury_type\" description=\"if the victim was injured, what type of injuries did the victim sustain?\"/>\n",
      "    <integer name=\"victim_count\" description=\"how many victims were there?\"/>\n",
      "    <string name=\"victim_sex\" description=\"what was the sex of the victim?\"/>\n",
      "    <string name=\"victime_ages\" description=\"what were the ages of the victims?\"/>\n",
      "    <string name=\"notes\" description=\"summary of what happened along with details of where the car theft occurred and how the child was alone in the car\"/>\n",
      "</output>\n",
      "\n",
      "\n",
      "\n",
      "ONLY return a valid JSON object (no other text is necessary). The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# take a look at the new QA template!\n",
    "print(fmt_qa_tmpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    text_qa_template=qa_prompt,\n",
    "    refine_template=refine_prompt,\n",
    "    llm_predictor=llm_predictor,\n",
    ")\n",
    "response = query_engine.query(\n",
    "    \"What city and state did the car theft occur in? Did the car theft result in a fatality? What date did the car theft occur? Where did the car theft occur? Did the victim sustain any injuries? What type of injuries did the victim sustain? How many victims were there\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\n",
      "\"fatal\": \"No\",\n",
      "\"date\": \"Dec. 16, 2023\",\n",
      "\"city\": \"San Francisco\",\n",
      "\"state\": \"California\",\n",
      "\"location\": \"Cool Guys Market\",\n",
      "\"victim_injuries\": \"N/A\",\n",
      "\"victim_injury_type\": \"N/A\",\n",
      "\"victim_count\": 1,\n",
      "\"victim_sex\": \"Female\",\n",
      "\"victime_ages\": \"2 years old\",\n",
      "\"notes\": \"Someone stole a parked SUV with a sleeping toddler in the back seat from outside Cool Guys Market. The child was found crying in the vehicle 11 minutes later and appeared to be unharmed.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the response object extract the structured data\n",
    "#structured_data = response.metadata\n",
    "structured_data = response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(structured_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read string into a dictionary\n",
    "import json\n",
    "structured_data = json.loads(structured_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fatal</th>\n",
       "      <th>date</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>location</th>\n",
       "      <th>victim_injuries</th>\n",
       "      <th>victim_injury_type</th>\n",
       "      <th>victim_count</th>\n",
       "      <th>victim_sex</th>\n",
       "      <th>victime_ages</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>Feb 25, 2022</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>California</td>\n",
       "      <td></td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>The victim was a child who was found safe and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fatal          date     city       state location victim_injuries  \\\n",
       "0    No  Feb 25, 2022  Alameda  California                      N/A   \n",
       "\n",
       "  victim_injury_type  victim_count victim_sex victime_ages  \\\n",
       "0                N/A             1        N/A          N/A   \n",
       "\n",
       "                                               notes  \n",
       "0  The victim was a child who was found safe and ...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the structured data into a pandas dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(structured_data, index=[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(r\"Y:\\Yoshi\\MIDS\\Datasci209\\Projects\\FinalProject\\Data\\ExampleReports\\KCCACT121523Notfatal.csv\", index=False)\n",
    "df.to_csv(r\"Y:\\Yoshi\\MIDS\\Datasci209\\Projects\\FinalProject\\Data\\ExampleReports\\KCCA_CT_JL_2_25_22_Not_Fatal.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
